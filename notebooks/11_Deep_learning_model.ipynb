{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c1a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Total Columns: 55 ---\n",
      "['Rk', 'Player', 'Nation', 'Pos', 'Squad', 'Age', 'Born', 'MP', 'Starts', 'Min_league', '90s', 'Gls_league', 'Ast_league', 'G+A', 'G-PK', 'PK', 'PKatt', 'CrdY', 'CrdR', 'xG_player', 'npxG', 'xAG_player', 'npxG+xAG', 'PrgC', 'PrgP', 'PrgR', 'Gls.1', 'Ast.1', 'G+A.1', 'G-PK.1', 'G+A-PK', 'xG.1', 'xAG.1', 'xG+xAG', 'npxG.1', 'npxG+xAG.1', 'Matches', 'Season', 'Rk_team', 'MP_team', 'W', 'D', 'L', 'GF', 'GA', 'GD', 'Pts', 'Pts/MP', 'Top Team Scorer', 'Goalkeeper', 'Notes', 'Min_ucl', 'Gls_ucl', 'Ast_ucl', 'UCL_progress']\n",
      "\n",
      "--- Checking for Duplicates ---\n",
      "‚úÖ No duplicates in raw file.\n",
      "\n",
      "--- Checking if Target Names Already Exist ---\n",
      "‚ö†Ô∏è Found 'Gls_league' - Renaming logic might cause a collision!\n",
      "‚ö†Ô∏è Found 'Ast_league' - Renaming logic might cause a collision!\n",
      "‚ö†Ô∏è Found 'Min_league' - Renaming logic might cause a collision!\n",
      "‚ö†Ô∏è Found 'xG_player' - Renaming logic might cause a collision!\n",
      "‚ö†Ô∏è Found 'UCL_progress' - Renaming logic might cause a collision!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- DeepBallonNet: Journalist-View Prediction Pipeline ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. FEATURE ENGINEERING\n",
    "# ==============================================================================\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- 1. Trophy Score ---\n",
    "    trophy = 0\n",
    "    \n",
    "    # Team Rank Points\n",
    "    if 'Rk_team' in df.columns: \n",
    "        rank = pd.to_numeric(df['Rk_team'], errors='coerce').fillna(0)\n",
    "        trophy += (rank == 1).astype(int) * 2\n",
    "        \n",
    "    # UCL Progress Points\n",
    "    if 'UCL_progress' in df.columns:\n",
    "        # Force string, strip whitespace\n",
    "        ucl = df['UCL_progress'].fillna('None').astype(str).str.strip()\n",
    "        trophy += (ucl == 'W').astype(int) * 3\n",
    "        trophy += (ucl == 'F').astype(int) * 1\n",
    "        \n",
    "    df['Trophy_Impact_Score'] = trophy\n",
    "\n",
    "    # --- 2. Big Game Score ---\n",
    "    # Using .get() ensures we default to 0 if a column is somehow missing\n",
    "    gls_l = df.get('Gls_league', pd.Series(0, index=df.index)).fillna(0)\n",
    "    ast_l = df.get('Ast_league', pd.Series(0, index=df.index)).fillna(0)\n",
    "    gls_u = df.get('Gls_ucl', pd.Series(0, index=df.index)).fillna(0)\n",
    "    ast_u = df.get('Ast_ucl', pd.Series(0, index=df.index)).fillna(0)\n",
    "\n",
    "    df['Big_Game_Score'] = (gls_l * 1.0) + (ast_l * 0.5) + (gls_u * 2.5) + (ast_u * 1.0)\n",
    "    \n",
    "    # --- 3. Dominance Ratio ---\n",
    "    # Use Gls_league if available, else default to 0\n",
    "    goals = df.get('Gls_league', 0)\n",
    "    team_gf = df.get('GF', 1).replace(0, 1) \n",
    "    df['Dominance_Ratio'] = goals / team_gf\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAIN MODEL (Historical Data)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Training Model on Historical Data ---\")\n",
    "try:\n",
    "    hist_df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    \n",
    "    # Safety: Clean any potential history duplicates\n",
    "    hist_df = hist_df.loc[:, ~hist_df.columns.duplicated()]\n",
    "    hist_df = hist_df.reset_index(drop=True)\n",
    "    \n",
    "    # Standardize history column names\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    hist_df.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Historical data not found!\")\n",
    "\n",
    "# Define Targets\n",
    "ballon_dor_history = { \n",
    "    '2023-2024': ['Rodri', 'Vin√≠cius J√∫nior', 'Jude Bellingham', 'Kylian Mbapp√©', 'Harry Kane'], \n",
    "    '2022-2023': ['Lionel Messi', 'Erling Haaland', 'Kylian Mbapp√©', 'Kevin De Bruyne', 'Rodri'], \n",
    "    '2021-2022': ['Karim Benzema', 'Sadio Man√©', 'Kevin De Bruyne', 'Robert Lewandowski', 'Mohamed Salah'], \n",
    "    '2018-2019': ['Lionel Messi', 'Virgil van Dijk', 'Cristiano Ronaldo', 'Sadio Man√©', 'Mohamed Salah'], \n",
    "    '2017-2018': ['Luka Modriƒá', 'Cristiano Ronaldo', 'Antoine Griezmann', 'Kylian Mbapp√©', 'Lionel Messi'], \n",
    "    '2016-2017': ['Cristiano Ronaldo', 'Lionel Messi', 'Neymar', 'Gianluigi Buffon', 'Luka Modriƒá'], \n",
    "    '2015-2016': ['Cristiano Ronaldo', 'Lionel Messi', 'Antoine Griezmann', 'Luis Su√°rez', 'Neymar'], \n",
    "    '2014-2015': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar', 'Robert Lewandowski', 'Luis Su√°rez'], \n",
    "    '2013-2014': ['Cristiano Ronaldo', 'Lionel Messi', 'Manuel Neuer', 'Arjen Robben', 'Thomas M√ºller'], \n",
    "    '2012-2013': ['Cristiano Ronaldo', 'Lionel Messi', 'Franck Rib√©ry', 'Zlatan Ibrahimoviƒá', 'Neymar'], \n",
    "    '2011-2012': ['Lionel Messi', 'Cristiano Ronaldo', 'Andr√©s Iniesta', 'Xavi', 'Radamel Falcao'], \n",
    "    '2010-2011': ['Lionel Messi', 'Cristiano Ronaldo', 'Xavi', 'Andr√©s Iniesta', 'Wayne Rooney'] \n",
    "}\n",
    "\n",
    "hist_df['Top_Candidate'] = 0\n",
    "for season, players in ballon_dor_history.items():\n",
    "    hist_df.loc[(hist_df['Season'] == season) & (hist_df['Player'].isin(players)), 'Top_Candidate'] = 1\n",
    "\n",
    "hist_df = engineer_features(hist_df)\n",
    "progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'Did Not Qualify': 7}\n",
    "hist_df['UCL_Progress_Rank'] = hist_df['UCL_progress'].astype(str).map(progress_mapping).fillna(7)\n",
    "\n",
    "features = ['Age', 'Min_league', 'Gls_league', 'Ast_league', 'xG_player', 'xAG_player', \n",
    "            'Gls_ucl', 'Ast_ucl', 'Min_ucl', 'Rk_team', 'Pts', 'UCL_Progress_Rank', \n",
    "            'Trophy_Impact_Score', 'Big_Game_Score', 'Dominance_Ratio']\n",
    "\n",
    "X = hist_df[features].fillna(0)\n",
    "y = hist_df['Top_Candidate']\n",
    "\n",
    "# Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train_res.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class PrecisionNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PrecisionNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.model(x)\n",
    "\n",
    "model = PrecisionNet(X_train.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([100.0]))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(150):\n",
    "    model.train(); optimizer.zero_grad()\n",
    "    loss = criterion(model(X_train_t), y_train_t)\n",
    "    loss.backward(); optimizer.step()\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026 (Safe Run)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Predicting 2026 Candidates... ---\")\n",
    "\n",
    "# Load\n",
    "df_2026 = pd.read_csv('../data/master_dataset_2026.csv', encoding='latin1')\n",
    "\n",
    "# --- THE FIX ---\n",
    "# 1. Wipe the Index clean to prevent \"duplicate labels\" error\n",
    "df_2026 = df_2026.reset_index(drop=True)\n",
    "\n",
    "# 2. Smart Rename\n",
    "# Since your file ALREADY has 'Gls_league' and NOT 'Gls', the rename below will just skip\n",
    "# the keys that are missing. This is exactly what we want.\n",
    "target_map = {\n",
    "    'xG': 'xG_player', 'xAG': 'xAG_player', \n",
    "    'Rk': 'Rk_team', 'Pts': 'Pts',\n",
    "    'Min': 'Min_league', 'Gls': 'Gls_league', 'Ast': 'Ast_league',\n",
    "    'UCL_Progress': 'UCL_progress'\n",
    "}\n",
    "df_2026.rename(columns=target_map, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"‚úÖ Data Loaded. Columns verified.\")\n",
    "\n",
    "# Engineer Features\n",
    "df_2026 = engineer_features(df_2026)\n",
    "\n",
    "# Map UCL\n",
    "progress_mapping_live = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'League Phase': 6, 'Did Not Qualify': 7}\n",
    "\n",
    "if 'UCL_progress' in df_2026.columns:\n",
    "    df_2026['UCL_progress'] = df_2026['UCL_progress'].astype(str)\n",
    "    df_2026['UCL_Progress_Rank'] = df_2026['UCL_progress'].str.strip().map(progress_mapping_live).fillna(7)\n",
    "else:\n",
    "    df_2026['UCL_Progress_Rank'] = 7\n",
    "\n",
    "# Ensure numeric\n",
    "for col in features:\n",
    "    if col not in df_2026.columns: df_2026[col] = 0\n",
    "    df_2026[col] = pd.to_numeric(df_2026[col], errors='coerce')\n",
    "\n",
    "# Predict\n",
    "X_live = df_2026[features].fillna(0)\n",
    "X_live_scaled = scaler.transform(X_live)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(model(torch.tensor(X_live_scaled, dtype=torch.float32))).numpy().flatten()\n",
    "\n",
    "df_2026['Model_Probability'] = probs\n",
    "\n",
    "# Scoring Logic\n",
    "max_goals = df_2026['Gls_league'].max() if df_2026['Gls_league'].max() > 0 else 1\n",
    "max_ucl = df_2026['Gls_ucl'].max() if df_2026['Gls_ucl'].max() > 0 else 1\n",
    "max_prob = df_2026['Model_Probability'].max() if df_2026['Model_Probability'].max() > 0 else 1\n",
    "\n",
    "df_2026['Norm_Goals'] = df_2026['Gls_league'] / max_goals\n",
    "df_2026['Norm_UCL'] = df_2026['Gls_ucl'] / max_ucl\n",
    "df_2026['Norm_Prob'] = df_2026['Model_Probability'] / max_prob\n",
    "\n",
    "df_2026['Journalist_Score'] = (df_2026['Norm_Goals'] * 0.40) + \\\n",
    "                              (df_2026['Norm_UCL'] * 0.25) + \\\n",
    "                              (df_2026['Norm_Prob'] * 0.35)\n",
    "                              \n",
    "final_ranking = df_2026.sort_values(by='Journalist_Score', ascending=False).drop_duplicates(subset=['Player'])\n",
    "\n",
    "print(\"\\nüèÜ Top 15 Ballon d'Or Candidates (Journalist View):\")\n",
    "display_cols = ['Player', 'Squad', 'Gls_league', 'Gls_ucl', 'Model_Probability', 'Journalist_Score']\n",
    "\n",
    "try:\n",
    "    display(final_ranking[display_cols].head(15))\n",
    "except NameError:\n",
    "    print(final_ranking[display_cols].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DeepBallonNet: Journalist-View Prediction Pipeline ---\n",
      "\n",
      "--- Training Model on Historical Data ---\n",
      "‚úÖ Model Trained.\n",
      "\n",
      "--- Model Evaluation on Test Data ---\n",
      "üìä Accuracy:  99.58%\n",
      "üéØ Precision: 30.00% (Target: >10%)\n",
      "üîé Recall:    22.22% (Target: >60%)\n",
      "‚öñÔ∏è F1 Score:  25.53%\n",
      "\n",
      "--- Predicting 2026 Candidates... ---\n",
      "üîß Repairing Player Names...\n",
      "‚úÖ Data Ready. Columns: 55\n",
      "\n",
      "üèÜ Top 15 Ballon d'Or Candidates (Journalist View):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Gls_league</th>\n",
       "      <th>Gls_ucl</th>\n",
       "      <th>Model_Probability</th>\n",
       "      <th>Journalist_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Erling Haaland</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Kylian Mbapp√©</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Harry Kane</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Luis D√≠az</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Juli√°n √Ålvarez</td>\n",
       "      <td>Atl√©tico Madrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.6420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Mason Greenwood</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Lautaro Mart√≠nez</td>\n",
       "      <td>Inter</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Jonathan Burkardt</td>\n",
       "      <td>Eint Frankfurt</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Marcus Rashford</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.6051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Fermin L√≥pez</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.5784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>Du√Ç¬öan Vlahoviƒá</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.5563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Lamine Yamal</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.5534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Ferr√°n Torres</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>0.5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Viktor Gy√∂keres</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.5481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Anthony Gordon</td>\n",
       "      <td>Newcastle Utd</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.5453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player            Squad  Gls_league  Gls_ucl  \\\n",
       "163      Erling Haaland  Manchester City          14   5.0000   \n",
       "746       Kylian Mbapp√©      Real Madrid          13   5.0000   \n",
       "1121         Harry Kane    Bayern Munich          13   5.0000   \n",
       "1028          Luis D√≠az    Bayern Munich           6   3.0000   \n",
       "476      Juli√°n √Ålvarez  Atl√©tico Madrid           7   2.0000   \n",
       "2007    Mason Greenwood        Marseille           8   1.0000   \n",
       "1623   Lautaro Mart√≠nez            Inter           4   4.0000   \n",
       "992   Jonathan Burkardt   Eint Frankfurt           6   2.0000   \n",
       "825     Marcus Rashford        Barcelona           2   4.0000   \n",
       "717        Fermin L√≥pez        Barcelona           3   3.0000   \n",
       "1805    Du√Ç¬öan Vlahoviƒá         Juventus           3   3.0000   \n",
       "938        Lamine Yamal        Barcelona           4   2.0000   \n",
       "909       Ferr√°n Torres        Barcelona           5   2.0000   \n",
       "162     Viktor Gy√∂keres          Arsenal           4   2.0000   \n",
       "147      Anthony Gordon    Newcastle Utd           0   4.0000   \n",
       "\n",
       "      Model_Probability  Journalist_Score  \n",
       "163              0.9907            0.9993  \n",
       "746              0.9927            0.9714  \n",
       "1121             0.9868            0.9694  \n",
       "1028             0.9671            0.6624  \n",
       "476              0.9701            0.6420  \n",
       "2007             0.9837            0.6254  \n",
       "1623             0.8822            0.6253  \n",
       "992              0.9730            0.6145  \n",
       "825              0.9868            0.6051  \n",
       "717              0.9719            0.5784  \n",
       "1805             0.9093            0.5563  \n",
       "938              0.9617            0.5534  \n",
       "909              0.8668            0.5485  \n",
       "162              0.9467            0.5481  \n",
       "147              0.9795            0.5453  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- DeepBallonNet: Journalist-View Prediction Pipeline ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. UTILITIES (Safe Rename & Text Repair)\n",
    "# ==============================================================================\n",
    "def safe_rename(df, rename_map):\n",
    "    \"\"\"Renames columns only if the TARGET doesn't already exist.\"\"\"\n",
    "    clean_map = {}\n",
    "    for source, target in rename_map.items():\n",
    "        if source in df.columns:\n",
    "            if target not in df.columns:\n",
    "                clean_map[source] = target\n",
    "    if clean_map:\n",
    "        df.rename(columns=clean_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_mojibake(text):\n",
    "    \"\"\"Fixes encoding errors.\"\"\"\n",
    "    if not isinstance(text, str): return text\n",
    "    \n",
    "    # 1. Manual Overrides\n",
    "    replacements = {\n",
    "        'Du\\x9a': 'Du≈°', 'Du≈°': 'Du≈°', \n",
    "        'Vlahovi': 'Vlahoviƒá',\n",
    "        'Gy√É¬∂keres': 'Gy√∂keres',\n",
    "        'Lewandowski': 'Lewandowski'\n",
    "    }\n",
    "    for bad, good in replacements.items():\n",
    "        if bad in text:\n",
    "            text = text.replace(bad, good)\n",
    "            \n",
    "    # 2. Standard Latin-1 fix\n",
    "    try:\n",
    "        return text.encode('latin-1').decode('utf-8')\n",
    "    except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "        return text\n",
    "\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- Trophy Score ---\n",
    "    trophy = 0\n",
    "    if 'Rk_team' in df.columns: \n",
    "        rank = pd.to_numeric(df['Rk_team'], errors='coerce').fillna(0)\n",
    "        trophy += (rank == 1).astype(int) * 2\n",
    "        \n",
    "    if 'UCL_progress' in df.columns:\n",
    "        ucl = df['UCL_progress'].astype(str).str.strip()\n",
    "        trophy += (ucl == 'W').astype(int) * 3\n",
    "        trophy += (ucl == 'F').astype(int) * 1\n",
    "    df['Trophy_Impact_Score'] = trophy\n",
    "\n",
    "    # --- Big Game Score ---\n",
    "    default_series = pd.Series(0, index=df.index)\n",
    "    gls_l = df.get('Gls_league', default_series).fillna(0)\n",
    "    ast_l = df.get('Ast_league', default_series).fillna(0)\n",
    "    gls_u = df.get('Gls_ucl', default_series).fillna(0)\n",
    "    ast_u = df.get('Ast_ucl', default_series).fillna(0)\n",
    "\n",
    "    df['Big_Game_Score'] = (gls_l * 1.0) + (ast_l * 0.5) + (gls_u * 2.5) + (ast_u * 1.0)\n",
    "    \n",
    "    # --- Dominance Ratio ---\n",
    "    team_gf = df.get('GF', 1).replace(0, 1) \n",
    "    df['Dominance_Ratio'] = gls_l / team_gf\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAIN MODEL (Historical)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Training Model on Historical Data ---\")\n",
    "try:\n",
    "    hist_df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    hist_df = hist_df.loc[:, ~hist_df.columns.duplicated()]\n",
    "    hist_df = hist_df.reset_index(drop=True)\n",
    "    \n",
    "    hist_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    hist_df = safe_rename(hist_df, hist_map)\n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Historical data not found!\")\n",
    "\n",
    "# History Winners\n",
    "ballon_dor_history = {\n",
    "    '2024-2025': ['Ousmane Dembele', 'Lamine Yamal', 'Vitinha', 'Raphinha', 'Mohammed Salah', 'Kylian Mbappe', 'Achraf Hakimi', 'Desire Doue', 'Kvicha Kvaratskhelia', 'Nuno Mendes'],\n",
    "    '2023-2024': ['Rodri', 'Vin√≠cius J√∫nior', 'Jude Bellingham', 'Dani Carvajal', 'Lautaro Martinez', 'Toni Kroos', 'Kylian Mbapp√©', 'Harry Kane', 'Phil Foden', 'Lamine Yamal'],\n",
    "    '2022-2023': ['Lionel Messi', 'Erling Haaland', 'Kylian Mbapp√©', 'Kevin De Bruyne', 'Rodri', 'Vin√≠cius J√∫nior', 'Juli√°n √Ålvarez', 'Victor Osimhen', 'Bernardo Silva', 'Luka Modriƒá'],\n",
    "    '2021-2022': ['Karim Benzema', 'Sadio Man√©', 'Kevin De Bruyne', 'Robert Lewandowski', 'Mohamed Salah', 'Kylian Mbapp√©', 'Thibaut Courtois', 'Vin√≠cius J√∫nior', 'Luka Modriƒá', 'Erling Haaland'],\n",
    "    '2020-2021': ['Lionel Messi', 'Robert Lewandowski', 'Jorginho', 'Karim Benzema', 'N\\'Golo Kant√©', 'Cristiano Ronaldo', 'Mohamed Salah', 'Kevin De Bruyne', 'Kylian Mbapp√©', 'Gianluigi Donnarumma'],\n",
    "    '2018-2019': ['Lionel Messi', 'Virgil van Dijk', 'Cristiano Ronaldo', 'Sadio Man√©', 'Mohamed Salah', 'Kylian Mbapp√©', 'Alisson', 'Robert Lewandowski', 'Bernardo Silva', 'Riyad Mahrez'],\n",
    "    '2017-2018': ['Luka Modriƒá', 'Cristiano Ronaldo', 'Antoine Griezmann', 'Kylian Mbapp√©', 'Lionel Messi', 'Mohamed Salah', 'Rapha√´l Varane', 'Eden Hazard', 'Kevin De Bruyne', 'Harry Kane'],\n",
    "    '2016-2017': ['Cristiano Ronaldo', 'Lionel Messi', 'Neymar', 'Gianluigi Buffon', 'Luka Modriƒá', 'Sergio Ramos', 'Kylian Mbapp√©', 'N\\'Golo Kant√©', 'Robert Lewandowski', 'Harry Kane'],\n",
    "    '2015-2016': ['Cristiano Ronaldo', 'Lionel Messi', 'Antoine Griezmann', 'Luis Su√°rez', 'Neymar', 'Gareth Bale', 'Riyad Mahrez', 'Jamie Vardy', 'Gianluigi Buffon', 'Pepe'],\n",
    "    '2014-2015': ['Lionel Messi', 'Cristiano Ronaldo', 'Neymar', 'Robert Lewandowski', 'Luis Su√°rez', 'Thomas M√ºller', 'Manuel Neuer', 'Eden Hazard', 'Andr√©s Iniesta', 'Alexis S√°nchez'],\n",
    "    '2013-2014': ['Cristiano Ronaldo', 'Lionel Messi', 'Manuel Neuer', 'Arjen Robben', 'Thomas M√ºller', 'Philipp Lahm', 'Neymar', 'James Rodr√≠guez', 'Toni Kroos', '√Ångel Di Mar√≠a'],\n",
    "    '2012-2013': ['Cristiano Ronaldo', 'Lionel Messi', 'Franck Rib√©ry', 'Zlatan Ibrahimoviƒá', 'Neymar', 'Andr√©s Iniesta', 'Robin van Persie', 'Arjen Robben', 'Gareth Bale', 'Andrea Pirlo'],\n",
    "    '2011-2012': ['Lionel Messi', 'Cristiano Ronaldo', 'Andr√©s Iniesta', 'Xavi', 'Radamel Falcao', 'Iker Casillas', 'Andrea Pirlo', 'Didier Drogba', 'Robin van Persie', 'Zlatan Ibrahimoviƒá'],\n",
    "    '2010-2011': ['Lionel Messi', 'Cristiano Ronaldo', 'Xavi', 'Andr√©s Iniesta', 'Wayne Rooney', 'Luis Su√°rez', 'Diego Forl√°n', 'Samuel Eto\\'o', 'Iker Casillas', 'Neymar']\n",
    "}\n",
    "\n",
    "hist_df['Top_Candidate'] = 0\n",
    "for season, players in ballon_dor_history.items():\n",
    "    hist_df.loc[(hist_df['Season'] == season) & (hist_df['Player'].isin(players)), 'Top_Candidate'] = 1\n",
    "\n",
    "hist_df = engineer_features(hist_df)\n",
    "progress_mapping = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'Did Not Qualify': 7}\n",
    "hist_df['UCL_Progress_Rank'] = hist_df['UCL_progress'].astype(str).map(progress_mapping).fillna(7)\n",
    "\n",
    "features = ['Age', 'Min_league', 'Gls_league', 'Ast_league', 'xG_player', 'xAG_player', \n",
    "            'Gls_ucl', 'Ast_ucl', 'Min_ucl', 'Rk_team', 'Pts', 'UCL_Progress_Rank', \n",
    "            'Trophy_Impact_Score', 'Big_Game_Score', 'Dominance_Ratio']\n",
    "\n",
    "X = hist_df[features].fillna(0)\n",
    "y = hist_df['Top_Candidate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train_res.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class PrecisionNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PrecisionNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.model(x)\n",
    "\n",
    "model = PrecisionNet(X_train.shape[1])\n",
    "\n",
    "# --- REALISM FIX: ADJUST WEIGHTS ---\n",
    "# Lowered from 12.0 to 3.0.\n",
    "# This calms the model down so it stops predicting \"everyone\" is a winner.\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6.0])) \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(150):\n",
    "    model.train(); optimizer.zero_grad()\n",
    "    loss = criterion(model(X_train_t), y_train_t)\n",
    "    loss.backward(); optimizer.step()\n",
    "\n",
    "# --- Model Evaluation on Test Data ---\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "print(\"\\n--- Model Evaluation on Test Data ---\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    \n",
    "    y_logits = model(X_test_t)\n",
    "    y_probs = torch.sigmoid(y_logits).numpy()\n",
    "    \n",
    "    # --- THRESHOLD FIX ---\n",
    "    # We only count it as a positive prediction if confidence is > 80%\n",
    "    # This significantly improves PRECISION (reduces false alarms)\n",
    "    y_pred = (y_probs > 0.70).astype(int) \n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"üìä Accuracy:  {acc:.2%}\")\n",
    "    print(f\"üéØ Precision: {prec:.2%} (Target: >10%)\")\n",
    "    print(f\"üîé Recall:    {rec:.2%} (Target: >60%)\")\n",
    "    print(f\"‚öñÔ∏è F1 Score:  {f1:.2%}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026 (With Realism Fixes)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Predicting 2026 Candidates... ---\")\n",
    "\n",
    "try:\n",
    "    df_2026 = pd.read_csv('../data/master_dataset_2026.csv', encoding='latin1')\n",
    "    df_2026 = df_2026.reset_index(drop=True)\n",
    "    df_2026 = df_2026.loc[:, ~df_2026.columns.duplicated()]\n",
    "\n",
    "    # Apply Text Repair\n",
    "    print(\"üîß Repairing Player Names...\")\n",
    "    for col in ['Player', 'Squad', 'Nation']:\n",
    "        if col in df_2026.columns:\n",
    "            df_2026[col] = df_2026[col].apply(fix_mojibake)\n",
    "    \n",
    "    # Safe Rename\n",
    "    target_map = {\n",
    "        'xG': 'xG_player', 'xAG': 'xAG_player', \n",
    "        'Rk': 'Rk_team', 'Pts': 'Pts',\n",
    "        'Min': 'Min_league', 'Gls': 'Gls_league', 'Ast': 'Ast_league',\n",
    "        'UCL_Progress': 'UCL_progress'\n",
    "    }\n",
    "    df_2026 = safe_rename(df_2026, target_map)\n",
    "    \n",
    "    print(f\"‚úÖ Data Ready. Columns: {len(df_2026.columns)}\")\n",
    "\n",
    "    # Engineer Features\n",
    "    df_2026 = engineer_features(df_2026)\n",
    "    \n",
    "    progress_mapping_live = {'W': 1, 'F': 2, 'SF': 3, 'QF': 4, 'R16': 5, 'GR': 6, 'League Phase': 6, 'Did Not Qualify': 7}\n",
    "    if 'UCL_progress' in df_2026.columns:\n",
    "        df_2026['UCL_progress'] = df_2026['UCL_progress'].astype(str)\n",
    "        df_2026['UCL_Progress_Rank'] = df_2026['UCL_progress'].str.strip().map(progress_mapping_live).fillna(7)\n",
    "    else:\n",
    "        df_2026['UCL_Progress_Rank'] = 7\n",
    "\n",
    "    for col in features:\n",
    "        if col not in df_2026.columns: df_2026[col] = 0\n",
    "        df_2026[col] = pd.to_numeric(df_2026[col], errors='coerce')\n",
    "\n",
    "    X_live = df_2026[features].fillna(0)\n",
    "    X_live_scaled = scaler.transform(X_live)\n",
    "\n",
    "    # --- REALISM FIX 2: Temperature Scaling ---\n",
    "    # Instead of sharp 0/1, we soften the probability curve\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(X_live_scaled, dtype=torch.float32))\n",
    "        \n",
    "        # Temperature > 1.0 makes the probabilities \"softer\"\n",
    "        temperature = 2.0 \n",
    "        probs = torch.sigmoid(logits / temperature).numpy().flatten()\n",
    "\n",
    "    df_2026['Model_Probability'] = probs\n",
    "\n",
    "    max_goals = df_2026['Gls_league'].max() if df_2026['Gls_league'].max() > 0 else 1\n",
    "    max_ucl = df_2026['Gls_ucl'].max() if df_2026['Gls_ucl'].max() > 0 else 1\n",
    "    max_prob = df_2026['Model_Probability'].max() if df_2026['Model_Probability'].max() > 0 else 1\n",
    "\n",
    "    df_2026['Norm_Goals'] = df_2026['Gls_league'] / max_goals\n",
    "    df_2026['Norm_UCL'] = df_2026['Gls_ucl'] / max_ucl\n",
    "    df_2026['Norm_Prob'] = df_2026['Model_Probability'] / max_prob\n",
    "\n",
    "    # Weights\n",
    "    df_2026['Journalist_Score'] = (df_2026['Norm_Goals'] * 0.40) + \\\n",
    "                                  (df_2026['Norm_UCL'] * 0.25) + \\\n",
    "                                  (df_2026['Norm_Prob'] * 0.35)\n",
    "                                  \n",
    "    final_ranking = df_2026.sort_values(by='Journalist_Score', ascending=False).drop_duplicates(subset=['Player'])\n",
    "\n",
    "    print(\"\\nüèÜ Top 15 Ballon d'Or Candidates (Journalist View):\")\n",
    "    display_cols = ['Player', 'Squad', 'Gls_league', 'Gls_ucl', 'Model_Probability', 'Journalist_Score']\n",
    "\n",
    "    try:\n",
    "        # Format probabilities to look like percentages\n",
    "        pd.options.display.float_format = '{:.4f}'.format\n",
    "        display(final_ranking[display_cols].head(15))\n",
    "    except NameError:\n",
    "        print(final_ranking[display_cols].head(15))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d0b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Elite High-Precision UCL Model ---\n",
      "Training Elite Ensemble...\n",
      "‚úÖ Model Trained.\n",
      "üèÜ Optimal Threshold: 0.40\n",
      "\n",
      "--- Elite Model Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Not Winner       0.98      0.89      0.93        45\n",
      "      Winner       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.63      0.78      0.67        48\n",
      "weighted avg       0.93      0.88      0.90        48\n",
      "\n",
      "\n",
      "--- 2026 UCL Winner Prediction ---\n",
      "Top 10 Contenders:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Squad</th>\n",
       "      <th>Win_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>0.171574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>0.034413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Marseille</td>\n",
       "      <td>0.015267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.010828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Napoli</td>\n",
       "      <td>0.009711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Dortmund</td>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Internazionale</td>\n",
       "      <td>0.004316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Squad  Win_Prob\n",
       "217        Bayern Munich  0.171574\n",
       "390  Paris Saint-Germain  0.034413\n",
       "382            Marseille  0.015267\n",
       "113            Barcelona  0.012749\n",
       "12               Arsenal  0.010828\n",
       "4              Liverpool  0.010660\n",
       "294               Napoli  0.009711\n",
       "204             Dortmund  0.009545\n",
       "110          Real Madrid  0.006659\n",
       "290       Internazionale  0.004316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training Elite High-Precision UCL Model ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD & PREPARE HISTORICAL DATA\n",
    "# ==============================================================================\n",
    "try:\n",
    "    historical_df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    historical_df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError: raise\n",
    "\n",
    "# --- Feature Engineering Function (Robust) ---\n",
    "def engineer_elite_features(df):\n",
    "    df = df.copy()\n",
    "    league_weights = {'Premier League': 1.0, 'La Liga': 0.95, 'Bundesliga': 0.85, 'Serie A': 0.85, 'Ligue 1': 0.75}\n",
    "    \n",
    "    # Handle missing 'League' column gracefully\n",
    "    if 'League' in df.columns:\n",
    "        df['League_Weight'] = df['League'].map(league_weights).fillna(0.7)\n",
    "        df['Is_Big_5'] = df['League'].isin(league_weights.keys()).astype(int)\n",
    "    else:\n",
    "        # Default weight if League is missing (assumes reasonably strong teams)\n",
    "        df['League_Weight'] = 0.85 \n",
    "        df['Is_Big_5'] = 1 \n",
    "\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Adj_Pts_Per_Game'] = (df['Pts'] / df['MP_team']) * df['League_Weight']\n",
    "    df['Adj_GD_Per_Game'] = (df['GD'] / df['MP_team']) * df['League_Weight']\n",
    "    \n",
    "    # Use aggregated column names directly\n",
    "    df['Squad_Goals'] = df.get('Agg_Gls_league', 0)\n",
    "    df['Squad_xG'] = df.get('Agg_xG', 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare Data\n",
    "ucl_df = historical_df[historical_df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "# Aggregate player stats\n",
    "player_agg = historical_df.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={\n",
    "    'Gls_league': 'Agg_Gls_league', \n",
    "    'xG_player': 'Agg_xG'\n",
    "})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "ucl_df = engineer_elite_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "# Define Features\n",
    "features = ['Adj_Pts_Per_Game', 'Adj_GD_Per_Game', 'Is_Big_5', 'Squad_Goals', 'Squad_xG']\n",
    "for col in features:\n",
    "    if col not in team_level_df.columns: team_level_df[col] = 0\n",
    "\n",
    "X = team_level_df[features].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_sc = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAINING (Elite Ensemble)\n",
    "# ==============================================================================\n",
    "print(\"Training Elite Ensemble...\")\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ucl_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ucl_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Model Trained.\")\n",
    "\n",
    "# Optimal Threshold\n",
    "probs = ucl_model.predict_proba(X_test_sc)[:, 1]\n",
    "best_thresh, best_f1 = 0.5, 0\n",
    "for t in np.arange(0.1, 0.9, 0.05):\n",
    "    preds = (probs >= t).astype(int)\n",
    "    score = f1_score(y_test, preds)\n",
    "    if score > best_f1: best_f1, best_thresh = score, t\n",
    "\n",
    "print(f\"üèÜ Optimal Threshold: {best_thresh:.2f}\")\n",
    "print(\"\\n--- Elite Model Report ---\")\n",
    "print(classification_report(y_test, (probs >= best_thresh).astype(int), target_names=['Not Winner', 'Winner']))\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. PREDICT 2026\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 2026 UCL Winner Prediction ---\")\n",
    "try:\n",
    "    # Load 2026 data\n",
    "    d_p = pd.read_csv('../data/combined_player_stats_2026.csv')\n",
    "    d_l = pd.read_csv('../data/combined_league_standings_2026.csv')\n",
    "    d_up = pd.read_csv('../data/ucl_team_progress_2026.csv')\n",
    "    d_us = pd.read_csv('../data/ucl_player_stats_2026.csv')\n",
    "    \n",
    "    current_season = '2025-2026'\n",
    "    for d in [d_p, d_l, d_up, d_us]: \n",
    "        d['Season']=current_season; d.columns=d.columns.str.strip()\n",
    "        if 'Squad' in d.columns: d['Squad']=d['Squad'].str.strip().replace({'Paris S-G':'Paris Saint-Germain','Inter':'Internazionale','Manchester Utd':'Manchester United','Leverkusen':'Bayer Leverkusen'})\n",
    "\n",
    "    m_k = ['Squad', 'Season']\n",
    "    if 'League' in d_p.columns and 'League' in d_l.columns: m_k.append('League')\n",
    "    df_26 = pd.merge(d_p, d_l, on=m_k, how='left', suffixes=('_player', '_team'))\n",
    "    df_26 = pd.merge(df_26, d_us[['Player','Squad','Season']], on=['Player','Squad','Season'], how='left')\n",
    "    df_26 = pd.merge(df_26, d_up, on=['Squad','Season'], how='left')\n",
    "    if 'UCL_Progress' in df_26.columns: df_26.rename(columns={'UCL_Progress':'UCL_progress'}, inplace=True)\n",
    "    df_26['UCL_progress'].fillna('Did Not Qualify', inplace=True)\n",
    "    \n",
    "    ucl_26 = df_26[df_26['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "    rename_26 = {'Gls':'Gls_league', 'xG':'xG_player', 'Pts':'Pts', 'MP':'MP_team', 'W':'W', 'GD':'GD', 'Rk':'Rk_team'}\n",
    "    ucl_26.rename(columns=rename_26, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Aggregation\n",
    "    p_agg = ucl_26.groupby(['Squad', 'Season'])[['Gls_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Agg_Gls_league', 'xG_player': 'Agg_xG'})\n",
    "    ucl_26 = pd.merge(ucl_26, p_agg, on=['Squad', 'Season'], how='left')\n",
    "    ucl_26 = ucl_26.drop_duplicates(subset=['Squad'])\n",
    "    \n",
    "    # Feature Engineering (Now Safe against missing 'League' column)\n",
    "    ucl_26 = engineer_elite_features(ucl_26)\n",
    "    \n",
    "    # Select Best Features & Scale\n",
    "    for col in features:\n",
    "        if col not in ucl_26.columns: ucl_26[col] = 0\n",
    "    \n",
    "    X_live = ucl_26[features].fillna(0)\n",
    "    # Use the same scaler from training!\n",
    "    X_live_sc = pd.DataFrame(scaler.transform(X_live), columns=features)\n",
    "    \n",
    "    # Predict\n",
    "    ucl_26['Win_Prob'] = ucl_model.predict_proba(X_live_sc)[:, 1]\n",
    "    print(\"Top 10 Contenders:\")\n",
    "    cols = ['Squad', 'Win_Prob']\n",
    "    if 'League' in ucl_26.columns: cols.insert(1, 'League')\n",
    "    display(ucl_26[cols].sort_values(by='Win_Prob', ascending=False).head(10))\n",
    "\n",
    "except Exception as e: print(f\"Prediction Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a50b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training UCL Ensemble Model ---\n",
      "‚úÖ Ensemble Model Trained.\n",
      "\n",
      ">>> Evaluating UCL Winner Model...\n",
      "\n",
      "--- Advanced Evaluation: Ensemble ---\n",
      "üèÜ Optimal Threshold: 0.2140\n",
      "   Max F1-Score: 0.1429\n",
      "   Precision at Optimal: 0.0909\n",
      "   Recall at Optimal:    0.3333\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 28.3\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Train and Evaluate UCL Ensemble Model ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Training UCL Ensemble Model ---\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('../data/master_dataset_2011-2025.csv')\n",
    "    rename_map = {'xG': 'xG_player', 'xAG': 'xAG_player', 'UCL_Progress': 'UCL_progress'}\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    raise Exception(\"Data not found!\")\n",
    "\n",
    "# 2. Feature Engineering (Elite UCL)\n",
    "def engineer_ucl_features(df):\n",
    "    df = df.copy()\n",
    "    df['MP_team'] = df['MP_team'].replace(0, 1)\n",
    "    df['Pts_Per_Game'] = df['Pts'] / df['MP_team']\n",
    "    df['Goal_Diff_Per_Game'] = df['GD'] / df['MP_team']\n",
    "    df['Win_Rate'] = df['W'] / df['MP_team']\n",
    "    df['Dominance_Score'] = (df['Win_Rate'] * 0.7) + (df['Goal_Diff_Per_Game'] * 0.3)\n",
    "    df['League_Pedigree'] = 1 / df['Rk_team'].replace(0, 20)\n",
    "    return df\n",
    "\n",
    "# 3. Prepare Team-Level Data\n",
    "ucl_df = df[df['UCL_progress'] != 'Did Not Qualify'].copy()\n",
    "ucl_df['UCL_Winner'] = np.where(ucl_df['UCL_progress'] == 'W', 1, 0)\n",
    "\n",
    "player_agg = df.groupby(['Squad', 'Season'])[['Gls_league', 'Ast_league', 'xG_player']].sum().reset_index().rename(columns={'Gls_league': 'Squad_Goals', 'Ast_league': 'Squad_Ast', 'xG_player': 'Squad_xG'})\n",
    "ucl_df = pd.merge(ucl_df, player_agg, on=['Squad', 'Season'], how='left')\n",
    "\n",
    "ucl_df = engineer_ucl_features(ucl_df)\n",
    "team_level_df = ucl_df.drop_duplicates(subset=['Squad', 'Season'], keep='first').copy()\n",
    "\n",
    "features_ucl = ['Pts_Per_Game', 'Goal_Diff_Per_Game', 'Win_Rate', 'Dominance_Score', 'League_Pedigree', 'Squad_Goals', 'Squad_xG', 'xG_team']\n",
    "# Handle missing xG_team for old seasons\n",
    "if 'xG_team' not in team_level_df.columns: team_level_df['xG_team'] = 0\n",
    "\n",
    "X = team_level_df[features_ucl].fillna(0)\n",
    "y = team_level_df['UCL_Winner']\n",
    "\n",
    "# Split & Scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Balance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Train Ensemble\n",
    "clf1 = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42, eval_metric='logloss')\n",
    "clf2 = lgb.LGBMClassifier(n_estimators=200, learning_rate=0.05, num_leaves=31, verbose=-1, random_state=42)\n",
    "clf3 = CatBoostClassifier(iterations=200, learning_rate=0.05, depth=5, verbose=0, random_seed=42)\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[('xgb', clf1), ('lgbm', clf2), ('cat', clf3)], voting='soft')\n",
    "ensemble_model.fit(X_train_res, y_train_res)\n",
    "print(\"‚úÖ Ensemble Model Trained.\")\n",
    "\n",
    "# 5. Run Advanced Evaluation (Using your function)\n",
    "if 'evaluate_model_advanced' in locals():\n",
    "    print(\"\\n>>> Evaluating UCL Winner Model...\")\n",
    "    evaluate_model_advanced(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "    calculate_top_k_proxy(ensemble_model, X_test_scaled, y_test, \"Ensemble\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è evaluation functions not found. Please run the previous cell containing 'evaluate_model_advanced'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb828a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Advanced Evaluation: Deep Learning (Ballon d'Or) ---\n",
      "üèÜ Optimal Threshold: 0.7485\n",
      "   Max F1-Score: 0.2857\n",
      "   Precision at Optimal: 0.3333\n",
      "   Recall at Optimal:    0.2500\n",
      "\n",
      "--- Advanced Evaluation: Ensemble (UCL) ---\n",
      "üèÜ Optimal Threshold: 0.0140\n",
      "   Max F1-Score: 0.1290\n",
      "   Precision at Optimal: 0.0714\n",
      "   Recall at Optimal:    0.6667\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Deep Learning): 171.2\n",
      "\n",
      "üìä Average Rank of True Winners in Test Set (Ensemble): 30.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# --- 1. Define the Advanced Evaluation Function (FIXED) ---\n",
    "def evaluate_model_advanced(model, X_test, y_test, model_type=\"Deep Learning\"):\n",
    "    print(f\"\\n--- Advanced Evaluation: {model_type} ---\")\n",
    "    \n",
    "    # Get Probabilities\n",
    "    # FIX: Check if \"Deep Learning\" is IN the string, not just equal to it\n",
    "    if \"Deep Learning\" in model_type:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X_test, torch.Tensor):\n",
    "                X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "            # Forward pass + Sigmoid\n",
    "            probs = torch.sigmoid(model(X_test)).numpy().flatten()\n",
    "            \n",
    "            if isinstance(y_test, torch.Tensor):\n",
    "                y_true = y_test.numpy().flatten()\n",
    "            else:\n",
    "                y_true = y_test\n",
    "    else: # Ensemble / XGBoost\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        y_true = y_test\n",
    "\n",
    "    # 2. Find Optimal Threshold (Maximize F1)\n",
    "    # Handle NaNs in y_true (just in case)\n",
    "    mask = ~np.isnan(y_true)\n",
    "    y_true = y_true[mask]\n",
    "    probs = probs[mask]\n",
    "    \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, probs)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    # Safety check for index bounds\n",
    "    if best_idx < len(thresholds):\n",
    "        best_thresh = thresholds[best_idx]\n",
    "    else:\n",
    "        best_thresh = 0.5\n",
    "        \n",
    "    best_f1 = f1_scores[best_idx]\n",
    "    \n",
    "    print(f\"üèÜ Optimal Threshold: {best_thresh:.4f}\")\n",
    "    print(f\"   Max F1-Score: {best_f1:.4f}\")\n",
    "    print(f\"   Precision at Optimal: {precisions[best_idx]:.4f}\")\n",
    "    print(f\"   Recall at Optimal:    {recalls[best_idx]:.4f}\")\n",
    "\n",
    "    return best_thresh\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. RUN ADVANCED EVALUATION (with Reconstructed Data)\n",
    "# ==============================================================================\n",
    "\n",
    "# Note: We assume the data reconstruction part from the previous cell ran successfully\n",
    "# and X_test_b_tensor, y_test_b_tensor, X_test_u_scaled, y_test_u are available.\n",
    "\n",
    "if 'model' in locals():\n",
    "    # Fix: String matching is now handled inside the function\n",
    "    best_thresh_bdo = evaluate_model_advanced(model, X_test_b_tensor, y_test_b, \"Deep Learning (Ballon d'Or)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'model' (Deep Learning) not found in memory.\")\n",
    "\n",
    "if 'ensemble_model' in locals():\n",
    "    best_thresh_ucl = evaluate_model_advanced(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble (UCL)\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'ensemble_model' not found in memory.\")\n",
    "\n",
    "\n",
    "# --- 3. Top-K Accuracy Proxy ---\n",
    "def calculate_top_k_proxy(model, X, y, model_type=\"Deep Learning\"):\n",
    "    if model_type == \"Deep Learning\":\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "             if not isinstance(X, torch.Tensor): X = torch.tensor(X, dtype=torch.float32)\n",
    "             probs = torch.sigmoid(model(X)).numpy().flatten()\n",
    "    else:\n",
    "        probs = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    results = pd.DataFrame({'Actual': y, 'Prob': probs})\n",
    "    winners = results[results['Actual'] == 1]\n",
    "    \n",
    "    if not winners.empty:\n",
    "        results['Rank'] = results['Prob'].rank(ascending=False)\n",
    "        avg_winner_rank = results[results['Actual'] == 1]['Rank'].mean()\n",
    "        print(f\"\\nüìä Average Rank of True Winners in Test Set ({model_type}): {avg_winner_rank:.1f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è No winners found in test set for {model_type}.\")\n",
    "\n",
    "if 'model' in locals(): calculate_top_k_proxy(model, X_test_b_tensor, y_test_b, \"Deep Learning\")\n",
    "if 'ensemble_model' in locals(): calculate_top_k_proxy(ensemble_model, X_test_u_scaled, y_test_u, \"Ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
